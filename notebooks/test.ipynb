{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f96bb84-d528-4f07-a0fd-7649e0016957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4da344-c55a-4fc5-baa6-5cdfa84f93b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03d666179e546518caefd06606290a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForTokenClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 97,255,424 || all params: 3,310,011,394 || trainable%: 2.9382\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "lora_config = LoraConfig(\n",
    "    r=64,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=128, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ") \n",
    "\n",
    "\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fca52af-bbb1-4d84-8d4d-b9d0c3c93900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForTokenClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (score): Linear(in_features=3072, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c005391-8cf6-4df1-aef1-1ba14b8e8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.directionality import AttentionExtractor, SymmetryScore, DirectionalityScore\n",
    "\n",
    "extractor = AttentionExtractor(\n",
    "    model=model,\n",
    "    q_path=\"model.layers[layer_idx].self_attn.q_proj\",\n",
    "    k_path=\"model.layers[layer_idx].self_attn.k_proj\",\n",
    "    # q_path=\"base_model.model.model.layers[layer_idx].self_attn.q_proj\",\n",
    "    # k_path=\"base_model.model.model.layers[layer_idx].self_attn.k_proj\",\n",
    "    attention_type=\"grouped\",\n",
    "    # is_lora=True, merge_lora=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455bfc88-3530-462d-b919-dc0cb52cdd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lora.Linear(\n",
       "  (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (default): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict(\n",
       "    (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "  )\n",
       "  (lora_B): ModuleDict(\n",
       "    (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "  )\n",
       "  (lora_embedding_A): ParameterDict()\n",
       "  (lora_embedding_B): ParameterDict()\n",
       "  (lora_magnitude_vector): ModuleDict()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = model.base_model.model.model.layers[0].self_attn.q_proj\n",
    "\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa604b67-3872-4473-ad8e-f11f37fd5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft.tuners.lora import LoraLayer\n",
    "\n",
    "isinstance(module, LoraLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b7f40d-3110-4a1a-9589-554d7b2bc075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.013316988945007324,\n",
       " 0.013686060905456543,\n",
       " 0.0078051090240478516,\n",
       " 0.009980559349060059,\n",
       " 0.02069699764251709,\n",
       " 0.0016776323318481445,\n",
       " 0.02029287815093994,\n",
       " 0.02415013313293457,\n",
       " 0.05804133415222168,\n",
       " 0.02527034282684326,\n",
       " 0.04807102680206299,\n",
       " 0.003994584083557129,\n",
       " 0.021612167358398438,\n",
       " 0.022856831550598145,\n",
       " 0.009163856506347656,\n",
       " 0.01067817211151123,\n",
       " 0.0046149492263793945,\n",
       " 0.019084453582763672,\n",
       " 0.013350486755371094,\n",
       " 0.009339094161987305,\n",
       " 0.0028172731399536133,\n",
       " 0.0029038190841674805,\n",
       " 0.002758502960205078,\n",
       " 0.012760281562805176,\n",
       " 0.006015419960021973,\n",
       " 0.004072666168212891,\n",
       " 0.024454712867736816,\n",
       " 0.005753040313720703]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = score()\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01173f-65fb-421c-8ab1-5f6dd5ed7616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f35e36-30ff-43b1-a9bb-c736e0e12637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60dd3fa-8a31-4499-87e0-068632475db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd8b01-38f5-432f-8033-a8ae619d23a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb4e9d9-e315-4b6e-9a7c-e6f2f3d79643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.013316988945007324,\n",
       " 0.013686060905456543,\n",
       " 0.0078051090240478516,\n",
       " 0.009980559349060059,\n",
       " 0.02069699764251709,\n",
       " 0.0016776323318481445,\n",
       " 0.02029287815093994,\n",
       " 0.02415013313293457,\n",
       " 0.05804133415222168,\n",
       " 0.02527034282684326,\n",
       " 0.04807102680206299,\n",
       " 0.003994584083557129,\n",
       " 0.021612167358398438,\n",
       " 0.022856831550598145,\n",
       " 0.009163856506347656,\n",
       " 0.01067817211151123,\n",
       " 0.0046149492263793945,\n",
       " 0.019084453582763672,\n",
       " 0.013350486755371094,\n",
       " 0.009339094161987305,\n",
       " 0.0028172731399536133,\n",
       " 0.0029038190841674805,\n",
       " 0.002758502960205078,\n",
       " 0.012760281562805176,\n",
       " 0.006015419960021973,\n",
       " 0.004072666168212891,\n",
       " 0.024454712867736816,\n",
       " 0.005753040313720703]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged lora\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1df1874-9024-4c62-96cc-8fe5772503ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014972120523452759"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9b285-3a5d-421c-9a0a-ef0c393e6a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a20583-1807-4dba-addd-93031dd2b17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54302b82-9b18-4c32-bc32-ea21f0272ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3072, out_features=3072, bias=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.q_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f792e450-cd0b-49f5-85ca-4e4ef24d6cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "score._score(torch.zeros_like(model.model.layers[0].self_attn.q_proj.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b1155-3dac-47cf-9f98-63399283fc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
