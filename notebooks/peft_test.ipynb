{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca38daf-371c-440c-aa6a-b046a010658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from src.models import MODELS_MAPPING\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f3cbfe-5111-4f07-821b-95e960df8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = MODELS_MAPPING.get(\n",
    "    \"llama\", {}\n",
    "    ).get(\"mntp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe947c5-6681-479d-b61a-2bc530e77706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.models.llama.biLlamaForMaskedNTP"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fec29e-de50-4a17-befb-dc5eee0f2f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2e717e8c024ca9ab510401c2744166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224d53c03c48421288a9ea76472da97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_class.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-3B\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbeeaac-135a-4983-9fe3-b7f1ed255ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75749a97-97ac-4358-9877-a185f06f9207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 97,255,424 || all params: 3,310,005,248 || trainable%: 2.9382\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=64,  # the dimension of the low-rank matrices\n",
    "    lora_alpha=128, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout=0.05, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=['o_proj', 'v_proj', \"q_proj\", \"k_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ") \n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b038de0-3c65-435c-ae4c-960947cc3830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0110,  0.0111,  0.0132,  ..., -0.0026, -0.0189,  0.0067],\n",
       "                      [ 0.0134,  0.0013,  0.0210,  ...,  0.0007,  0.0327, -0.0026],\n",
       "                      [ 0.0251,  0.0204,  0.0284,  ..., -0.0012, -0.0008, -0.0079],\n",
       "                      ...,\n",
       "                      [-0.0083,  0.0036,  0.0050,  ..., -0.0024, -0.0020, -0.0052],\n",
       "                      [-0.0083,  0.0036,  0.0050,  ..., -0.0024, -0.0020, -0.0052],\n",
       "                      [-0.0083,  0.0036,  0.0050,  ..., -0.0024, -0.0020, -0.0052]],\n",
       "                     dtype=torch.float16))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57810944-c2b8-4945-9c96-824283daee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759be3b-e1ec-48e1-8e90-ae535d63cdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a9510-4718-4fa4-98fb-1963251efd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46088ca9-0f2e-426b-a44d-960275f02d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bb8d170-c9d5-473b-a0b6-8f0b04c8e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-3B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e0a6ae9-a1bf-4857-bedf-ed59d37fc927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7521b5fd-8084-4009-9632-709804b988af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "PreTrainedTokenizerFast has no attribute add",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1108\u001b[0m, in \u001b[0;36mSpecialTokensMixin.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(attr_as_tokens) \u001b[38;5;28;01mif\u001b[39;00m attr_as_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m-> 1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: PreTrainedTokenizerFast has no attribute add"
     ]
    }
   ],
   "source": [
    "tokenizer.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d542cad-f5e1-494d-85c0-a7c2fb056d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
